{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401b9d73-5aa1-4ffe-aaa5-ca03ea05d481",
   "metadata": {},
   "source": [
    "# First Agent\n",
    "We'll use smolagents, a library that provides a freamework for developing your agents with ease. not suitable for production grade\n",
    "\n",
    "## What does this agent do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d8b79-976f-4362-9208-9ccf4e51e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, tool, InferenceClientModel\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3da4c7-eec3-468b-a1e4-5d1fe3c58495",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577abdb-e409-473c-b024-60385419db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM model\n",
    "model_id = 'Qwen/Qwen3-4B-Instruct-2507'\n",
    "model = InferenceClientModel(\n",
    "    max_tokens = 2096,\n",
    "    model_id = model_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b03bae-9e1c-4395-9a17-c066b401f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply use the model to generate response, not an agent here\n",
    "agent = CodeAgent(model= model, tools = [])\n",
    "result = agent.run(\"I need your help.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3886ba-8c3a-4194-920f-12afcac3a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tools\n",
    "@tool\n",
    "def my_custom_tool (arg:str) -> str:\n",
    "    \"\"\"A dummy tool that does nothing\n",
    "    Args:\n",
    "        arg: dummy arg\n",
    "    \"\"\"\n",
    "    return \"Here is your magic tool that does nothing. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43131e77-96a9-4b3d-a7e2-95b11f64d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "The CodeAgent assumes complex tasks might require multiple steps of reasoning and code execution:\n",
    "\n",
    "Step 1: Analyze the problem and write initial code\n",
    "Step 2: Examine results and decide if more work is needed\n",
    "Step 3: Write additional code if necessary\n",
    "Continue: Until the task is \"complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b5468-cc75-4d86-b258-8646e89bfb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent with dummy tool\n",
    "from smolagents.agents import EMPTY_PROMPT_TEMPLATES\n",
    "prompt_templates = EMPTY_PROMPT_TEMPLATES.copy()\n",
    "\n",
    "prompt_templates['system_prompt'] = \"\"\"\n",
    "        You are an assistant with access to a special tool called `my_custom_tool`.\n",
    "        Whenever the user asks to \"see magic\", \"show magic\", \"do magic\", or otherwise refers\n",
    "        to something magical, you MUST call `my_custom_tool` with the user‚Äôs provided phrase\n",
    "        as the `arg` argument. \n",
    "\n",
    "        Format your reasoning as follows:\n",
    "        \n",
    "        Thoughts: I need to call the magic tool.\n",
    "        <code>\n",
    "        # Your python code here\n",
    "        my_custom_tool(arg=\"the magic tool\")\n",
    "        </code>\n",
    "        Observation: \"Here is your magic tool that does nothing. \"\n",
    "        \n",
    "        - If the user does not provide an argument, pass \"magic\" as the default.\n",
    "        - Do not try to answer the request directly when it involves magic‚Äîalways use the tool.\n",
    "        - After calling the tool, return its output to the user.\n",
    "        - For all other requests not related to magic, just answer normally without calling the tool.\n",
    "        \"\"\" \n",
    "\n",
    "agent_dummy = CodeAgent(\n",
    "    model= model, \n",
    "    tools = [my_custom_tool],\n",
    "    prompt_templates = prompt_templates,\n",
    "    max_steps = 1\n",
    ")\n",
    "result = agent_dummy.run(\"Show me some magic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db5dc3-a882-45c5-a8d7-3aebcab31c32",
   "metadata": {},
   "source": [
    "Let‚Äôs look at an example. When Alfred wants to search for catering services and party ideas, a CodeAgent would generate and run Python code like this:\n",
    "\n",
    "Copied\n",
    "for query in [\n",
    "    \"Best catering services in Gotham City\", \n",
    "    \"Party theme ideas for superheroes\"\n",
    "]:\n",
    "    print(web_search(f\"Search for: {query}\"))\n",
    "A ToolCallingAgent would instead create a JSON structure:\n",
    "\n",
    "Copied\n",
    "[\n",
    "    {\"name\": \"web_search\", \"arguments\": \"Best catering services in Gotham City\"},\n",
    "    {\"name\": \"web_search\", \"arguments\": \"Party theme ideas for superheroes\"}\n",
    "]\n",
    "This JSON blob is then used to execute the tool calls.\n",
    "\n",
    "While smolagents primarily focuses on CodeAgents since they perform better overall, ToolCallingAgents can be effective for simple systems that don‚Äôt require variable handling or complex tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d814e-2aea-4c6d-8e7e-d6a3b87220b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent\n",
    "prompt_templates1 = EMPTY_PROMPT_TEMPLATES.copy()\n",
    "prompt_templates1['system_prompt'] = \"\"\"\n",
    "        You are an assistant with access to a special tool called `my_custom_tool`.\n",
    "        Whenever the user asks to \"see magic\", \"show magic\", \"do magic\", or otherwise refers\n",
    "        to something magical, you MUST call `my_custom_tool` with the user‚Äôs provided phrase\n",
    "        as the `arg` argument. \n",
    "        \n",
    "        Thoughts: I need to call the magic tool.\n",
    "        Action: {\"name\": \"my_custom_tool\", \"arguments\": \"magic\"}\n",
    "        Observation: \"Here is your magic tool that does nothing. \"\n",
    "        \n",
    "        - If the user does not provide an argument, pass \"magic\" as the default.\n",
    "        - Do not try to answer the request directly when it involves magic‚Äîalways use the tool.\n",
    "        - After calling the tool, return its output to the user.\n",
    "        - For all other requests not related to magic, just answer normally without calling the tool.\n",
    "        \"\"\" \n",
    "agent_dummy2 = ToolCallingAgent(\n",
    "    model= InferenceClientModel(), \n",
    "    tools = [my_custom_tool],\n",
    "    prompt_templates = prompt_templates1,\n",
    "    max_steps = 1\n",
    ")\n",
    "result2 = agent_dummy2.run(\"Show me some magic!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30192f5b-61a2-4b73-aba4-632083529db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "@tool\n",
    "def get_time()->str:\n",
    "    \"\"\"A tool that fetches the current local time.\"\"\"\n",
    "    try:\n",
    "        now = datetime.now()\n",
    "        return f\"üïí It's {now.strftime('%I:%M %p')} on {now.strftime('%A, %B %d')}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error getting time: {str(e)}\"\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69968d1f-c844-47b6-ba88-00a6f430a8e6",
   "metadata": {},
   "source": [
    "The CodeAgent assumes complex tasks might require multiple steps of reasoning and code execution:\n",
    "\n",
    "Step 1: Analyze the problem and write initial code\n",
    "Step 2: Examine results and decide if more work is needed\n",
    "Step 3: Write additional code if necessary\n",
    "Continue: Until the task is \"complete\"\n",
    "\n",
    "In smolagents, the FinalAnswerTool is a special built-in tool that lets an agent end its reasoning loop and return the final answer to the user.\n",
    "\n",
    "Think of it as the \"exit door\" for the agent:\n",
    "\n",
    "During a reasoning chain, the agent might call tools, write Python, or fetch external info.\n",
    "\n",
    "Once it has the actual result it wants to deliver, it must call FinalAnswerTool with that answer.\n",
    "\n",
    "This prevents the agent from looping forever and makes it explicit: ‚ÄúI‚Äôm done, here‚Äôs the output.‚Äù\n",
    "Why it matters\n",
    "\n",
    "Without FinalAnswerTool, the agent might just keep reasoning and calling tools until it hits max_steps. By calling FinalAnswerTool, it signals to the framework that it has produced the answer for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969b63f-b70c-42c3-a245-708ac23a4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import FinalAnswerTool\n",
    "final_answer = FinalAnswerTool()\n",
    "prompt_templates2 = EMPTY_PROMPT_TEMPLATES.copy()\n",
    "\n",
    "prompt_templates2['system_prompt'] = \"\"\"\n",
    "    You are an assistant agent. \n",
    "    You have access to the following tools:\n",
    "    \n",
    "    1. get_time -> Fetches and returns the current local time in a human-friendly format.\n",
    "    2. final_answer -> Used to return your final response to the user.\n",
    "\n",
    "    Here is an example:\n",
    "    Task: What time is it?\n",
    "    Thoughts: I need to call the get_time tool. After retriving the time, I need to call the final_answer tool to return the results.\n",
    "    <code>\n",
    "    get_time()\n",
    "    final_answer()\n",
    "    </code>\n",
    "    \n",
    "    Guidelines:\n",
    "    - If a tool is needed, call it directly. Do not guess values you could fetch from tools.\n",
    "    - After using tools and gathering results, provide the final reply to the user using final_answer.\n",
    "    - Keep answers concise and clear.\n",
    "    - Never expose tool call syntax to the user, only the results.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "agent_time = CodeAgent(\n",
    "    model= model, \n",
    "    tools = [get_time, final_answer],\n",
    "    max_steps = 2,\n",
    "    verbosity_level = 2,\n",
    "    prompt_templates = prompt_templates2\n",
    "    \n",
    ")\n",
    "result = agent_time.run(\"What time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7d8b6-9505-46fc-a390-5435d4f8ce84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6731a6a2-5a9c-4ef6-9bb9-5f769c3c8c95",
   "metadata": {},
   "source": [
    "The parameter verbosity_level controls how much the agent logs or ‚Äúthinks out loud‚Äù during its reasoning and tool use.\n",
    "\n",
    "Levels\n",
    "\n",
    "verbosity_level=0 ‚Üí Silent/minimal logging\n",
    "\n",
    "Only the final result is returned.\n",
    "\n",
    "No intermediate reasoning, tool calls, or debug info shown.\n",
    "\n",
    "verbosity_level=1 ‚Üí Normal / concise logging (default)\n",
    "\n",
    "Prints the agent‚Äôs steps (like Thoughts: ..., tool calls, and observations), but in a summarized way.\n",
    "\n",
    "Good balance if you want to see what‚Äôs happening without too much clutter.\n",
    "\n",
    "verbosity_level=2 ‚Üí Verbose / full trace\n",
    "\n",
    "Shows detailed chain-of-thought (well, the structured reasoning it‚Äôs allowed to show), intermediate code snippets, tool arguments, and outputs.\n",
    "\n",
    "Useful for debugging or when developing custom tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ef9f7-420b-45f0-bf02-b860a1b18e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "some built-in tools\n",
    "https://huggingface.co/docs/smolagents/reference/default_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63d742-223b-4b55-9efc-a3d462db6a46",
   "metadata": {},
   "source": [
    "# Observability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded091a6-7a3e-4db8-b103-2fa16ee83a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "from langfuse import get_client\n",
    "from langfuse import Langfuse\n",
    "\n",
    "LANGFUSE_SECRET_KEY=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "LANGFUSE_PUBLIC_KEY=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "LANGFUSE_HOST=os.getenv(\"LANGFUSE_HOST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e275d-c1ea-41fa-916f-8366614b2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify connection\n",
    "langfuse = get_client()\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da7508-d978-4f6b-a214-83f0ee8ff470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "\n",
    "SmolagentsInstrumentor().instrument()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3ce12-e2ac-40f3-902c-3ab148f657ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f02b4-1718-4fe4-8bfb-6594d6674a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How can I know the time?\"\n",
    "result = agent_time.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0945346-fe66-4f31-b92a-0a5011478af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6275f1a-3d2d-4dc6-b76d-682db719c3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
